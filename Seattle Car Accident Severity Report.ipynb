{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "# Seattle Car Accident Severity Report\n\nTable of Contents\n1. Introduction\n2. Data\n3. Methodology\n4. Results & Evaluation\n5. Discussion\n6. Conclusion\n\n## 1. Introduction | Business Understanding \nIn an effort to reduce the frequency of car collisions in a community, an algorithm must be developed to predict the severity of an accident given the current weather, road and visibility conditions. In an application, drivers will be alerted of the severity level when conditions are above code 0."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_ba6956f1aba54bac8182f4fc43408457 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='T1a2GOt4X0SjEdOgVN5L-ddq4Hsr0na_PJcRwfaY2Pvi',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_ba6956f1aba54bac8182f4fc43408457.get_object(Bucket='courseracapstone-donotdelete-pr-rifgb1pzejei9b',Key='Data-Collisions.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data = pd.read_csv(body)\ndf_data.head()\n",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n",
                    "name": "stderr"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 1,
                    "data": {
                        "text/plain": "   SEVERITYCODE           X          Y  OBJECTID  INCKEY  COLDETKEY REPORTNO  \\\n0             2 -122.323148  47.703140         1    1307       1307  3502005   \n1             1 -122.347294  47.647172         2   52200      52200  2607959   \n2             1 -122.334540  47.607871         3   26700      26700  1482393   \n3             1 -122.334803  47.604803         4    1144       1144  3503937   \n4             2 -122.306426  47.545739         5   17700      17700  1807429   \n\n    STATUS      ADDRTYPE   INTKEY  ... ROADCOND                LIGHTCOND  \\\n0  Matched  Intersection  37475.0  ...      Wet                 Daylight   \n1  Matched         Block      NaN  ...      Wet  Dark - Street Lights On   \n2  Matched         Block      NaN  ...      Dry                 Daylight   \n3  Matched         Block      NaN  ...      Dry                 Daylight   \n4  Matched  Intersection  34387.0  ...      Wet                 Daylight   \n\n  PEDROWNOTGRNT  SDOTCOLNUM SPEEDING ST_COLCODE  \\\n0           NaN         NaN      NaN         10   \n1           NaN   6354039.0      NaN         11   \n2           NaN   4323031.0      NaN         32   \n3           NaN         NaN      NaN         23   \n4           NaN   4028032.0      NaN         10   \n\n                                          ST_COLDESC  SEGLANEKEY  \\\n0                                  Entering at angle           0   \n1  From same direction - both going straight - bo...           0   \n2                             One parked--one moving           0   \n3                   From same direction - all others           0   \n4                                  Entering at angle           0   \n\n   CROSSWALKKEY  HITPARKEDCAR  \n0             0             N  \n1             0             N  \n2             0             N  \n3             0             N  \n4             0             N  \n\n[5 rows x 38 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEVERITYCODE</th>\n      <th>X</th>\n      <th>Y</th>\n      <th>OBJECTID</th>\n      <th>INCKEY</th>\n      <th>COLDETKEY</th>\n      <th>REPORTNO</th>\n      <th>STATUS</th>\n      <th>ADDRTYPE</th>\n      <th>INTKEY</th>\n      <th>...</th>\n      <th>ROADCOND</th>\n      <th>LIGHTCOND</th>\n      <th>PEDROWNOTGRNT</th>\n      <th>SDOTCOLNUM</th>\n      <th>SPEEDING</th>\n      <th>ST_COLCODE</th>\n      <th>ST_COLDESC</th>\n      <th>SEGLANEKEY</th>\n      <th>CROSSWALKKEY</th>\n      <th>HITPARKEDCAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>-122.323148</td>\n      <td>47.703140</td>\n      <td>1</td>\n      <td>1307</td>\n      <td>1307</td>\n      <td>3502005</td>\n      <td>Matched</td>\n      <td>Intersection</td>\n      <td>37475.0</td>\n      <td>...</td>\n      <td>Wet</td>\n      <td>Daylight</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>Entering at angle</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-122.347294</td>\n      <td>47.647172</td>\n      <td>2</td>\n      <td>52200</td>\n      <td>52200</td>\n      <td>2607959</td>\n      <td>Matched</td>\n      <td>Block</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>Wet</td>\n      <td>Dark - Street Lights On</td>\n      <td>NaN</td>\n      <td>6354039.0</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>From same direction - both going straight - bo...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-122.334540</td>\n      <td>47.607871</td>\n      <td>3</td>\n      <td>26700</td>\n      <td>26700</td>\n      <td>1482393</td>\n      <td>Matched</td>\n      <td>Block</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>Dry</td>\n      <td>Daylight</td>\n      <td>NaN</td>\n      <td>4323031.0</td>\n      <td>NaN</td>\n      <td>32</td>\n      <td>One parked--one moving</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-122.334803</td>\n      <td>47.604803</td>\n      <td>4</td>\n      <td>1144</td>\n      <td>1144</td>\n      <td>3503937</td>\n      <td>Matched</td>\n      <td>Block</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>Dry</td>\n      <td>Daylight</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23</td>\n      <td>From same direction - all others</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>-122.306426</td>\n      <td>47.545739</td>\n      <td>5</td>\n      <td>17700</td>\n      <td>17700</td>\n      <td>1807429</td>\n      <td>Matched</td>\n      <td>Intersection</td>\n      <td>34387.0</td>\n      <td>...</td>\n      <td>Wet</td>\n      <td>Daylight</td>\n      <td>NaN</td>\n      <td>4028032.0</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>Entering at angle</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 38 columns</p>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 2. Data Understanding\nOur predictor or target variable will be 'SEVERITYCODE' because it is used to measure the severity of an accident from 0 to 4 within the dataset. Attributes used to weigh the severity of an accident are 'WEATHER', 'ROADCOND' and 'LIGHTCOND'.\n\nSeverity codes are as follows:\n\n0 : Little to no Probability (Clear Conditions)<br>\n1 : Very Low Probability - Chance or Property Damage<br>\n2 : Low Probability - Chance of Injury<br>\n3 : Mild Probability - Chance of Serious Injury<br>\n4 : High Probability - Chance of Fatality<br>\n\n### Extract Dataset & Convert\nIn it's original form, this data is not fit for analysis. For one, there are many columns that we will not use for this model. Also, most of the features are of type object, when they should be numerical type.\n\nWe must use label encoding to covert the features to our desired data type."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Drop all columns with no predictive value for the context of this project\ncolData = df_data.drop(columns = ['OBJECTID', 'SEVERITYCODE.1', 'REPORTNO', 'INCKEY', 'COLDETKEY', \n              'X', 'Y', 'STATUS','ADDRTYPE',\n              'INTKEY', 'LOCATION', 'EXCEPTRSNCODE',\n              'EXCEPTRSNDESC', 'SEVERITYDESC', 'INCDATE',\n              'INCDTTM', 'JUNCTIONTYPE', 'SDOT_COLCODE',\n              'SDOT_COLDESC', 'PEDROWNOTGRNT', 'SDOTCOLNUM',\n              'ST_COLCODE', 'ST_COLDESC', 'SEGLANEKEY',\n              'CROSSWALKKEY', 'HITPARKEDCAR', 'PEDCOUNT', 'PEDCYLCOUNT',\n              'PERSONCOUNT', 'VEHCOUNT', 'COLLISIONTYPE',\n              'SPEEDING', 'UNDERINFL', 'INATTENTIONIND'])\n\n# Label Encoding\n# Convert column to category\ncolData[\"WEATHER\"] = colData[\"WEATHER\"].astype('category')\ncolData[\"ROADCOND\"] = colData[\"ROADCOND\"].astype('category')\ncolData[\"LIGHTCOND\"] = colData[\"LIGHTCOND\"].astype('category')\n\n# Assign variable to new column for analysis\ncolData[\"WEATHER_CAT\"] = colData[\"WEATHER\"].cat.codes\ncolData[\"ROADCOND_CAT\"] = colData[\"ROADCOND\"].cat.codes\ncolData[\"LIGHTCOND_CAT\"] = colData[\"LIGHTCOND\"].cat.codes\n\ncolData.head(5)",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 2,
                    "data": {
                        "text/plain": "   SEVERITYCODE   WEATHER ROADCOND                LIGHTCOND  WEATHER_CAT  \\\n0             2  Overcast      Wet                 Daylight            4   \n1             1   Raining      Wet  Dark - Street Lights On            6   \n2             1  Overcast      Dry                 Daylight            4   \n3             1     Clear      Dry                 Daylight            1   \n4             2   Raining      Wet                 Daylight            6   \n\n   ROADCOND_CAT  LIGHTCOND_CAT  \n0             8              5  \n1             8              2  \n2             0              5  \n3             0              5  \n4             8              5  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEVERITYCODE</th>\n      <th>WEATHER</th>\n      <th>ROADCOND</th>\n      <th>LIGHTCOND</th>\n      <th>WEATHER_CAT</th>\n      <th>ROADCOND_CAT</th>\n      <th>LIGHTCOND_CAT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Overcast</td>\n      <td>Wet</td>\n      <td>Daylight</td>\n      <td>4</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Raining</td>\n      <td>Wet</td>\n      <td>Dark - Street Lights On</td>\n      <td>6</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Overcast</td>\n      <td>Dry</td>\n      <td>Daylight</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Clear</td>\n      <td>Dry</td>\n      <td>Daylight</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Raining</td>\n      <td>Wet</td>\n      <td>Daylight</td>\n      <td>6</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now let's check the data types of the new columns in our dataframe. Moving forward, we will only use the new columns for our analysis."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "colData.dtypes",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 3,
                    "data": {
                        "text/plain": "SEVERITYCODE        int64\nWEATHER          category\nROADCOND         category\nLIGHTCOND        category\nWEATHER_CAT          int8\nROADCOND_CAT         int8\nLIGHTCOND_CAT        int8\ndtype: object"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Analyzing Value Counts"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "colData[\"SEVERITYCODE\"].value_counts()",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 4,
                    "data": {
                        "text/plain": "1    136485\n2     58188\nName: SEVERITYCODE, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "colData[\"WEATHER\"].value_counts()",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 5,
                    "data": {
                        "text/plain": "Clear                       111135\nRaining                      33145\nOvercast                     27714\nUnknown                      15091\nSnowing                        907\nOther                          832\nFog/Smog/Smoke                 569\nSleet/Hail/Freezing Rain       113\nBlowing Sand/Dirt               56\nSevere Crosswind                25\nPartly Cloudy                    5\nName: WEATHER, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "colData[\"ROADCOND\"].value_counts()",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 6,
                    "data": {
                        "text/plain": "Dry               124510\nWet                47474\nUnknown            15078\nIce                 1209\nSnow/Slush          1004\nOther                132\nStanding Water       115\nSand/Mud/Dirt         75\nOil                   64\nName: ROADCOND, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "colData[\"LIGHTCOND\"].value_counts()",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 7,
                    "data": {
                        "text/plain": "Daylight                    116137\nDark - Street Lights On      48507\nUnknown                      13473\nDusk                          5902\nDawn                          2502\nDark - No Street Lights       1537\nDark - Street Lights Off      1199\nOther                          235\nDark - Unknown Lighting         11\nName: LIGHTCOND, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Balancing the Dataset\nOur target variable SEVERITYCODE is only 42% balanced. In fact, severitycode in class 1 is nearly three times the size of class 2.\n\nWe can fix this by downsampling the majority class."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.utils import resample",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Seperate majority and minority classes\ncolData_majority = colData[colData.SEVERITYCODE==1]\ncolData_minority = colData[colData.SEVERITYCODE==2]\n\n#Downsample majority class\ncolData_majority_downsampled = resample(colData_majority,\n                                        replace=False,\n                                        n_samples=58188,\n                                        random_state=123)\n\n# Combine minority class with downsampled majority class\ncolData_balanced = pd.concat([colData_majority_downsampled, colData_minority])\n\n# Display new class counts\ncolData_balanced.SEVERITYCODE.value_counts()",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 9,
                    "data": {
                        "text/plain": "2    58188\n1    58188\nName: SEVERITYCODE, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Methodology \nOur data is now ready to be fed into machine learning models.\n\nWe will use the following models:\n\n### K-Nearest Neighbor (KNN)\nKNN will help us predict the severity code of an outcome by finding the most similar to data point within k distance.\n\n### Decision Tree\nA decision tree model gives us a layout of all possible outcomes so we can fully analyze the consequences of a decision. It context, the decision tree observes all possible outcomes of different weather conditions.\n\n### Logistic Regression\nBecause our dataset only provides us with two severity code outcomes, our model will only predict one of those two classes. This makes our data binary, which is perfect to use with logistic regression.\n\n#### Initialization\nDefine X and y"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import numpy as np\nX = np.asarray(colData_balanced[['WEATHER_CAT', 'ROADCOND_CAT', 'LIGHTCOND_CAT']])\nX[0:5]",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 10,
                    "data": {
                        "text/plain": "array([[ 6,  8,  2],\n       [ 1,  0,  5],\n       [10,  7,  8],\n       [ 1,  0,  5],\n       [ 1,  0,  5]], dtype=int8)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "y = np.asarray(colData_balanced['SEVERITYCODE'])\ny [0:5]\n",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 11,
                    "data": {
                        "text/plain": "array([1, 1, 1, 1, 1])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Normalize the dataset"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn import preprocessing\nX = preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]",
            "execution_count": 12,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int8 was converted to float64 by StandardScaler.\n  warnings.warn(msg, DataConversionWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int8 was converted to float64 by StandardScaler.\n  warnings.warn(msg, DataConversionWarning)\n",
                    "name": "stderr"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 12,
                    "data": {
                        "text/plain": "array([[ 1.15236718,  1.52797946, -1.21648407],\n       [-0.67488   , -0.67084969,  0.42978835],\n       [ 2.61416492,  1.25312582,  2.07606076],\n       [-0.67488   , -0.67084969,  0.42978835],\n       [-0.67488   , -0.67084969,  0.42978835]])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Train/Test Split"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)\n",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Train set: (81463, 3) (81463,)\nTest set: (34913, 3) (34913,)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### K-Nearest Neighbors (KNN)"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Building the KNN Model\nfrom sklearn.neighbors import KNeighborsClassifier\n\nk = 25",
            "execution_count": 14,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Train Model & Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh\n\nKyhat = neigh.predict(X_test)\nKyhat[0:5]",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 15,
                    "data": {
                        "text/plain": "array([2, 2, 1, 1, 2])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Decision Tree"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Building the Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ncolDataTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 7)\ncolDataTree\ncolDataTree.fit(X_train,y_train)",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 16,
                    "data": {
                        "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=7,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Train Model & Predict\npredTree = colDataTree.predict(X_test)\nprint (predTree [0:5])\nprint (y_test [0:5])\n",
            "execution_count": 17,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "[2 2 1 1 2]\n[2 2 1 1 1]\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install pydotplus \n!pip install graphviz ",
            "execution_count": 18,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting pydotplus\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/bf/62567830b700d9f6930e9ab6831d6ba256f7b0b730acb37278b0ccdffacf/pydotplus-2.0.2.tar.gz (278kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 286kB 7.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pyparsing>=2.0.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pydotplus) (2.3.1)\nBuilding wheels for collected packages: pydotplus\n  Building wheel for pydotplus (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/35/7b/ab/66fb7b2ac1f6df87475b09dc48e707b6e0de80a6d8444e3628\nSuccessfully built pydotplus\nInstalling collected packages: pydotplus\nSuccessfully installed pydotplus-2.0.2\nCollecting graphviz\n  Downloading https://files.pythonhosted.org/packages/62/dc/9dd6a6b9b8977248e165e075b109eea6e8eac71faa28ca378c3d98e54fbe/graphviz-0.14.1-py2.py3-none-any.whl\nInstalling collected packages: graphviz\nSuccessfully installed graphviz-0.14.1\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Logistic Regression"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Building the LR Model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLR = LogisticRegression(C=6, solver='liblinear').fit(X_train,y_train)\nLR",
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 19,
                    "data": {
                        "text/plain": "LogisticRegression(C=6, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n          tol=0.0001, verbose=0, warm_start=False)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Train Model & Predicr\nLRyhat = LR.predict(X_test)\nLRyhat",
            "execution_count": 20,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 20,
                    "data": {
                        "text/plain": "array([1, 2, 1, ..., 2, 2, 2])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nyhat_prob = LR.predict_proba(X_test)\nyhat_prob",
            "execution_count": 21,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 21,
                    "data": {
                        "text/plain": "array([[0.57295252, 0.42704748],\n       [0.47065071, 0.52934929],\n       [0.67630201, 0.32369799],\n       ...,\n       [0.46929132, 0.53070868],\n       [0.47065071, 0.52934929],\n       [0.46929132, 0.53070868]])"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Results & Evaluation"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss",
            "execution_count": 22,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### K-Nearest Neighbor"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Jaccard Similarity Score\njaccard_similarity_score(y_test, Kyhat)\n",
            "execution_count": 23,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 23,
                    "data": {
                        "text/plain": "0.564001947698565"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# F1-SCORE\nf1_score(y_test, Kyhat, average='macro')",
            "execution_count": 24,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 24,
                    "data": {
                        "text/plain": "0.5401775308974308"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Model is most accurate when k is 25."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Decision Tree"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Jaccard Similarity Score\njaccard_similarity_score(y_test, DTyhat)",
            "execution_count": 25,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'DTyhat' is not defined",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-25-12a7d96c9dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Jaccard Similarity Score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjaccard_similarity_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDTyhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m: name 'DTyhat' is not defined"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# F1-SCORE\nf1_score(y_test, DTyhat, average='macro')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Model is most accurate with a max depth of 7."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Logistic Regression"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Jaccard Similarity Score\njaccard_similarity_score(y_test, LRyhat)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# F1-SCORE\nf1_score(y_test, LRyhat, average='macro')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# LOGLOSS\nyhat_prob = LR.predict_proba(X_test)\nlog_loss(y_test, yhat_prob)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Model is most accurate when hyperparameter C is 6."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Discussion \nIn the beginning of this notebook, we had categorical data that was of type 'object'. This is not a data type that we could have fed through an algorithm, so label encoding was used to created new classes that were of type int8; a numerical data type.\n\nAfter solving that issue we were presented with another - imbalanced data. As mentioned earlier, class 1 was nearly three times larger than class 2. The solution to this was downsampling the majority class with sklearn's resample tool. We downsampled to match the minority class exactly with 58188 values each.\n\nOnce we analyzed and cleaned the data, it was then fed through three ML models; K-Nearest Neighbor, Decision Tree and Logistic Regression. Although the first two are ideal for this project, logistic regression made the most sense because of its binary nature.\n\nEvaluation metrics used to test the accuracy of our models were jaccard index, f-1 score and logloss for logistic regression. Choosing different k, max depth and hyperamater C values helped to improve our accuracy to be the best possible."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Conclusion \nBased on historical data from weather conditions pointing to certain classes, we can conclude that particular weather conditions have a somewhat impact on whether or not travel could result in property damage (class 1) or injury (class 2)."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}